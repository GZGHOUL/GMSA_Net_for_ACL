# modules/processor.py
import numpy as np
import pandas as pd
from scipy.signal import kaiserord, firwin, filtfilt, butter
from utils import parse_features_to_array

class SignalProcessor:
    def __init__(self, fs=60, params=None):
        self.fs = fs
        self.params = params or {}

    def _notch_filter(self, data):
        nyq = self.fs / 2
        freq = self.params.get('notch_freq', 10)
        width = self.params.get('width', 2)
        ripple = self.params.get('ripple_db', 60)
        
        low = max(0.01, freq - width/2)
        high = min(nyq - 0.01, freq + width/2)
        
        N, beta = kaiserord(ripple, width / nyq)
        if N % 2 == 0: N += 1
        taps = firwin(N, [low/nyq, high/nyq], window=('kaiser', beta), pass_zero='bandstop')
        return filtfilt(taps, 1.0, data, axis=0)

    def _lowpass_filter(self, data):
        nyq = self.fs / 2
        cutoff = self.params.get('cutoff', 6)
        order = self.params.get('order', 6)
        b, a = butter(order, cutoff / nyq, btype='low')
        return filtfilt(b, a, data, axis=0)

    def process_features(self, features_array):
        """åº”ç”¨æ»¤æ³¢"""
        filtered = self._notch_filter(features_array)
        filtered = self._lowpass_filter(filtered)
        return filtered

class DataCleaner:
    @staticmethod
    def remove_no_record(df):
        """åˆ é™¤æ— è®°å½•çš„æ ·æœ¬å¹¶é‡ç½® person_id"""
        print(f"æ¸…æ´—å‰æ ·æœ¬æ•°: {len(df)}")
        df_clean = df[df['injure_label'] != 'æ— è®°å½•'].copy()
        # é‡ç½® person_id: æ¯ä¸¤ä¸ªäºº(å·¦+å³)ä¸ºä¸€ä¸ªID
        # æ³¨æ„ï¼šå¿…é¡»å…ˆreset_indexç¡®ä¿é¡ºåº
        df_clean.reset_index(drop=True, inplace=True)
        new_ids = (np.arange(len(df_clean)) // 2) + 1
        df_clean['person_id'] = new_ids.astype(int)
        print(f"æ¸…æ´—åæ ·æœ¬æ•°: {len(df_clean)}")
        return df_clean

    @staticmethod
    def fix_shape_and_filter(df, processor):
        """ä¿®æ­£å½¢çŠ¶ (padding) å¹¶åº”ç”¨æ»¤æ³¢"""
        fixed_count = 0
        processed_features = []
        
        for idx, row in df.iterrows():
            features = parse_features_to_array(row['features'])
            
            # 1. å½¢çŠ¶ä¿®æ­£ (Padding)
            target_len = 600
            if features.shape[0] < target_len:
                missing = target_len - features.shape[0]
                padding = np.tile(features[-1, :], (missing, 1))
                features = np.vstack([features, padding])
                fixed_count += 1
            
            # 2. ä¿¡å·å¤„ç† (Filtering)
            features = processor.process_features(features)
            processed_features.append(features.tolist())
            
        df['features'] = processed_features
        print(f"å·²ä¿®æ­£(Padding) {fixed_count} æ¡æ•°æ®å½¢çŠ¶ã€‚")
        return df

    @staticmethod
    def drop_invalid_samples(df):
        """
        æ£€æŸ¥å¹¶åˆ é™¤åŒ…å« NaN æˆ– Inf çš„æ ·æœ¬ã€‚
        ã€å®‰å…¨ç­–ç•¥ã€‘å¦‚æœæŸäººçš„å…¶ä¸­ä¸€æ¡è…¿æ•°æ®æ— æ•ˆï¼Œåˆ™åˆ é™¤è¯¥äººçš„æ‰€æœ‰æ•°æ®ï¼ˆç¡®ä¿å·¦å³è…¿æˆå¯¹ï¼‰ã€‚
        """
        initial_count = len(df)
        
        def is_valid(features_list):
            # è½¬ä¸º numpy æ•°ç»„æ£€æŸ¥
            arr = np.array(features_list)
            return not (np.isnan(arr).any() or np.isinf(arr).any())

        # 1. åˆæ­¥ç­›é€‰ï¼šæ‰¾å‡ºå“ªäº›è¡Œæ˜¯æ— æ•ˆçš„
        # is_valid_row æ˜¯ä¸€ä¸ª boolean Series (True=æœ‰æ•ˆ, False=æ— æ•ˆ)
        is_valid_row = df['features'].apply(is_valid)
        
        # 2. æ‰¾å‡º"åäºº"ï¼šå“ªäº› person_id æ‹¥æœ‰è‡³å°‘ä¸€æ¡æ— æ•ˆæ•°æ®
        # å–å is_valid_row å¾—åˆ°æ— æ•ˆè¡Œï¼Œç„¶åæå–è¿™äº›è¡Œçš„ person_id
        invalid_person_ids = df[~is_valid_row]['person_id'].unique()
        
        if len(invalid_person_ids) > 0:
            print(f"âš ï¸ å‘ç° {len(invalid_person_ids)} ä¸ªå—è¯•è€…å­˜åœ¨æ— æ•ˆæ•°æ®(NaN/Inf)ã€‚")
            print(f"   å—å½±å“ ID: {list(invalid_person_ids)}")
            
            # 3. è¿åç­–ç•¥ï¼šå‰”é™¤è¿™äº›äººçš„æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬ä»–ä»¬çš„å¥åº·è…¿ï¼‰
            # ç­›é€‰å‡º person_id ä¸åœ¨ invalid_person_ids ä¸­çš„è¡Œ
            df_clean = df[~df['person_id'].isin(invalid_person_ids)].copy()
            
            dropped_count = initial_count - len(df_clean)
            print(f"ğŸš¨ä»¥æ­¤è§¦å‘æˆå¯¹åˆ é™¤ç­–ç•¥ï¼šå…±å‰”é™¤ {dropped_count} æ¡æ ·æœ¬ï¼ˆç¡®ä¿å—å½±å“IDçš„å·¦å³è…¿å®Œå…¨ç§»é™¤ï¼‰ã€‚")
            
            # é‡æ–° reset_index ä»¥é˜²æ­¢ç´¢å¼•æ–­å±‚
            df_clean.reset_index(drop=True, inplace=True)
            return df_clean
            
        else:
            print("âœ… æœªå‘ç°æ— æ•ˆæ ·æœ¬ï¼Œæ•°æ®é›†å®Œæ•´ã€‚")
            return df